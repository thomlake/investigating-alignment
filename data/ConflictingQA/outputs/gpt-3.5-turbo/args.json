{
  "run": {
    "instance_file": "./data/ConflictingQA/instances/data.jsonl",
    "output_dir": "./data/ConflictingQA/outputs/"
  },
  "openai_params": {
    "model": "gpt-3.5-turbo",
    "temperature": 0.5,
    "response_format": null,
    "n": 5,
    "max_tokens": 1024
  }
}